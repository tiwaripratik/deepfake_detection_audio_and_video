{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install mtcnn"
      ],
      "metadata": {
        "id": "l-0bBaOvLIo6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pip install facenet-pytorch"
      ],
      "metadata": {
        "id": "-qNUo_bTLpWR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pip install gradio"
      ],
      "metadata": {
        "id": "a1a3fVRyLpZn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pip install grad-cam"
      ],
      "metadata": {
        "id": "dzZDAVLELpcu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "85DJ8rbiLpgI"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import torch\n",
        "import torch.nn.functional as F\n",
        "from facenet_pytorch import MTCNN, InceptionResnetV1\n",
        "from pytorch_grad_cam import GradCAM\n",
        "from pytorch_grad_cam.utils.model_targets import ClassifierOutputTarget\n",
        "from pytorch_grad_cam.utils.image import show_cam_on_image\n",
        "from PIL import Image\n",
        "import cv2\n",
        "import matplotlib.pyplot as plt\n",
        "from google.colab.patches import cv2_imshow\n",
        "from google.colab import files\n",
        "import shutil\n",
        "\n",
        "\n",
        "class FaceRecognition:\n",
        "    def __init__(self, output_folder, model_checkpoint, device='cpu'):\n",
        "        self.output_folder = output_folder\n",
        "        self.model = InceptionResnetV1(pretrained=\"vggface2\", classify=True, num_classes=1, device=device)\n",
        "        self.mtcnn = MTCNN(\n",
        "            post_process=False,\n",
        "            min_face_size=20,\n",
        "            thresholds=[0.6, 0.7, 0.7],\n",
        "            factor=0.709,\n",
        "            device=device\n",
        "        )\n",
        "        self.device = device\n",
        "        self.load_model_checkpoint(model_checkpoint)\n",
        "\n",
        "    def load_model_checkpoint(self, model_checkpoint):\n",
        "        checkpoint = torch.load(model_checkpoint, map_location=torch.device('cpu'))\n",
        "        self.model.load_state_dict(checkpoint['model_state_dict'])\n",
        "        self.model.to(self.device)\n",
        "        self.model.eval()\n",
        "\n",
        "    def predict(self, input_image):\n",
        "        face = self.mtcnn(input_image)\n",
        "        if face is None:\n",
        "            raise Exception('No face detected')\n",
        "\n",
        "        face = face.unsqueeze(0)  # Add the batch dimension\n",
        "        face = F.interpolate(face, size=(256, 256), mode='bilinear', align_corners=False)\n",
        "\n",
        "        prev_face = face.squeeze(0).permute(1, 2, 0).cpu().detach().int().numpy()\n",
        "        prev_face = prev_face.astype('uint8')\n",
        "\n",
        "        face = face.to(self.device, dtype=torch.float32) / 255.0\n",
        "        face_image_to_plot = face.squeeze(0).permute(1, 2, 0).cpu().detach().int().numpy()\n",
        "\n",
        "        target_layers = [self.model.block8.branch1[-1]]\n",
        "        use_cuda = True if torch.cuda.is_available() else False\n",
        "        cam = GradCAM(model=self.model, target_layers=target_layers)\n",
        "        targets = [ClassifierOutputTarget(0)]\n",
        "\n",
        "        grayscale_cam = cam(input_tensor=face, targets=targets, eigen_smooth=True)\n",
        "        grayscale_cam = grayscale_cam[0, :]\n",
        "        visualization = show_cam_on_image(face_image_to_plot, grayscale_cam, use_rgb=True)\n",
        "        face_with_mask = cv2.addWeighted(prev_face, 1, visualization, 0.5, 0)\n",
        "\n",
        "        with torch.no_grad():\n",
        "            output = torch.sigmoid(self.model(face).squeeze(0))\n",
        "            prediction = \"real\" if output.item() < 0.5 else \"fake\"\n",
        "\n",
        "            real_prediction = 1 - output.item()\n",
        "            fake_prediction = output.item()\n",
        "\n",
        "            confidences = {\n",
        "                'real': real_prediction,\n",
        "                'fake': fake_prediction\n",
        "            }\n",
        "\n",
        "        return confidences, face_with_mask\n",
        "\n",
        "    def process_video(self, video_path):\n",
        "        cap = cv2.VideoCapture(video_path)\n",
        "        frame_count = 0\n",
        "        end_time = cv2.getTickCount() + 30 * cv2.getTickFrequency()  # 30 seconds\n",
        "\n",
        "        while True:\n",
        "            if cv2.waitKey(1) == ord('x') or cv2.getTickCount() > end_time:\n",
        "                break\n",
        "\n",
        "            ret, frame = cap.read()\n",
        "            if not ret:\n",
        "                print(\"End of video or error reading frame.\")\n",
        "                break\n",
        "\n",
        "            # Detect faces\n",
        "            boxes, probs = self.mtcnn.detect(frame)\n",
        "            if boxes is not None:\n",
        "                for box in boxes:\n",
        "                    x, y, width, height = box.astype(int)\n",
        "                    face = frame[y:y + height, x:x + width]\n",
        "\n",
        "                    # Save the face\n",
        "                    cv2.imwrite(os.path.join(self.output_folder, f\"face_{frame_count}.jpg\"), face)\n",
        "\n",
        "                    # Draw rectangle around the face\n",
        "                    cv2.rectangle(frame, (x, y), (x + width, y + height), (255, 0, 0), 2)\n",
        "\n",
        "            frame_count += 1\n",
        "            # cv2_imshow(frame)\n",
        "\n",
        "        # Release video capture\n",
        "        cap.release()\n",
        "\n",
        "        print(\"Faces saved in:\", self.output_folder)\n",
        "\n",
        "    def upload_and_process_video(self):\n",
        "        # Upload video file\n",
        "        uploaded = files.upload()\n",
        "\n",
        "        # Move the uploaded video to the specified folder\n",
        "        for file_name in uploaded.keys():\n",
        "            video_path = os.path.join(self.output_folder, file_name)\n",
        "            with open(video_path, 'wb') as f:\n",
        "                f.write(uploaded[file_name])\n",
        "            print(\"Video uploaded:\", file_name)\n",
        "\n",
        "        # Process the uploaded video\n",
        "        self.process_video(video_path)\n",
        "\n",
        "        # Process the extracted faces\n",
        "        self.process_images()\n",
        "\n",
        "\n",
        "\n",
        "        # Delete the extracted images and video\n",
        "        self.delete_images_and_video()\n",
        "\n",
        "        # Stop the program\n",
        "        os._exit(0)\n",
        "\n",
        "    def process_images(self):\n",
        "        # Get a list of all image files in the output folder\n",
        "        image_files = [f for f in os.listdir(self.output_folder) if f.lower().endswith(('.png', '.jpg', '.jpeg', '.gif', '.bmp'))]\n",
        "\n",
        "        # List to store all predictions\n",
        "        predictions = []\n",
        "\n",
        "        for image_file in image_files:\n",
        "            # Open the image\n",
        "            image_path = os.path.join(self.output_folder, image_file)\n",
        "            image = Image.open(image_path)\n",
        "\n",
        "            # Call the predict function\n",
        "            confidences, image_with_mask = self.predict(image)\n",
        "            plt.imshow(image_with_mask)\n",
        "            plt.title(f\"Image: {image_file} with Mask Overlay\")\n",
        "            plt.axis('off')\n",
        "            plt.show()\n",
        "\n",
        "            # Store the prediction\n",
        "            if confidences['real'] > confidences['fake']:\n",
        "                predictions.append(\"real\")\n",
        "            else:\n",
        "                predictions.append(\"fake\")\n",
        "\n",
        "        # Count the votes\n",
        "        vote_count = {\n",
        "            \"real\": predictions.count(\"real\"),\n",
        "            \"fake\": predictions.count(\"fake\")\n",
        "        }\n",
        "\n",
        "        # Determine the final result\n",
        "        if vote_count[\"real\"] > vote_count[\"fake\"]:\n",
        "            final_result = \"Real\"\n",
        "        else:\n",
        "            final_result = \"Fake\"\n",
        "\n",
        "        # Print vote count and final result\n",
        "        print(\"Vote Count:\")\n",
        "        print(\"Real:\", vote_count[\"real\"])\n",
        "        print(\"Fake:\", vote_count[\"fake\"])\n",
        "        print(\"Final Result:\", final_result)\n",
        "\n",
        "    def delete_images_and_video(self):\n",
        "        \"\"\"Delete all image files and video from the output folder.\"\"\"\n",
        "        for filename in os.listdir(self.output_folder):\n",
        "            file_path = os.path.join(self.output_folder, filename)\n",
        "            if os.path.isfile(file_path):\n",
        "                if filename.lower().endswith(('.jpg', '.jpeg', '.png', '.avi', '.mp4')):\n",
        "                    try:\n",
        "                        os.remove(file_path)\n",
        "                        print(f\"Deleted {file_path}\")\n",
        "                    except Exception as e:\n",
        "                        print(f\"Error deleting {file_path}: {e}\")\n",
        "\n",
        "# Example usage\n",
        "output_folder = \"/content/drive/MyDrive/Colab Notebooks/Images_detection\"\n",
        "model_checkpoint = \"/content/drive/MyDrive/Colab Notebooks/resnetinceptionv1_epoch_32.pth\"\n",
        "\n",
        "face_recognition = FaceRecognition(output_folder, model_checkpoint)\n",
        "face_recognition.upload_and_process_video()\n"
      ],
      "metadata": {
        "id": "cZt2zNWvLmra"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "V1g5yoMGLmum"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "f5xLo5PWLmx7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "lLbvDkyLLCZZ"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}